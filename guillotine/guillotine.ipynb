{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do\n",
    "In this notebook is treated the game of the Guillotine which is broadcast every evening on Rai Uno on Italian television.\n",
    "\n",
    "The competitor is presented with five pairs of words, of which he must choose one and of which one is the right clue and the other is an intruder; if he chooses the right one, the prize money remains intact, otherwise it is halved.\n",
    "\n",
    "**Once all five clues have been found, the competitor has a minute to think about what the word that binds to each of them may be. If he guesses the word he wins the prize pool, otherwise he wins nothing. The champion returns by right in the next episode.**\n",
    "\n",
    "So, we need to implement an algorithm that, given 5 words, return the 6th. The sixth word has to be strongly related to the other five."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm\n",
    "Our algorithm searches within a dataset (composed by us) all the sentences in which at least one word of the 5 dates appears. These sentences are saved and pre-processed by tokenizing them (and removing stop words). Then the word that occurs most in all the selected sentences is selected. We weight more the words that appears in sentences for different test words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The dataset was composed by combining:\n",
    "  - Titles of movies scraped from https://linguatools.org/tools/corpora/wikipedia-parallel-titles-corpora/ and transformed in txt format\n",
    "  - Titles of italian songs scraped from https://www.midi-miti-mici.it/musica-midi/elenco-canzoni-A_B.asp\n",
    "  - Common saying scraped https://www.sololibri.net/Modi-di-dire-i-piu-conosciuti.html & https://it.wikipedia.org/wiki/Glossario_delle_frasi_fatte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from typing import Set, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(path: str) -> List[str]:\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        rows = f.read().splitlines()\n",
    "    return rows\n",
    "\n",
    "stop_words = set(stopwords.words('italian'))\n",
    "dataset = import_dataset('data/corpus.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing of a sentence\n",
    "def bag_of_words(sentence: str) -> Set[str]:\n",
    "    return set(remove_stopwords(tokenize_sentence(remove_punctuation(sentence))))\n",
    "\n",
    "\n",
    "# Remove stopwords from a word list\n",
    "def remove_stopwords(words: List[str]) -> List[str]:\n",
    "    return [value.lower() for value in words if value.lower() not in stop_words]\n",
    "\n",
    "\n",
    "# Get tokens from sentence\n",
    "def tokenize_sentence(sentence: str) -> List[str]:\n",
    "    words = []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    for tag in nltk.pos_tag(word_tokenize(sentence)):\n",
    "        words.append(lmtzr.lemmatize(tag[0]).lower())\n",
    "    return words\n",
    "\n",
    "\n",
    "# Remove punctuation and multiple spaces\n",
    "def remove_punctuation(sentence: str) -> str:\n",
    "    return re.sub('\\s\\s+', ' ', re.sub(r'[^\\w\\s]', ' ', sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_answer(test_words: List[str]) -> str:\n",
    "    # Counting each word of each sentence (sentence in which occurs one word among those in input)\n",
    "    word_counter = defaultdict(lambda: defaultdict(int))\n",
    "    for test_word in test_words:\n",
    "        for row in dataset:\n",
    "            if test_word.lower() in [w.lower() for w in row.split(' ')]: # If the test word occur in the current sentence (of the dataset)\n",
    "                sentence_words = bag_of_words(row) - {test_word} # Sentence tokenization\n",
    "                for sentence_word in sentence_words:\n",
    "                    word_counter[sentence_word][test_word] += 1\n",
    "\n",
    "    scores = {}\n",
    "    for sentence_word, inner_dict in word_counter.items():\n",
    "        scores[sentence_word] = len(inner_dict) * sum(inner_dict.values()) # Weighted sum (we weigh more the terms that appear in sentences concerning different test_words)\n",
    "\n",
    "    answer = max(scores, key=scores.get) # Get key with max value (max count)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: sassolino, ciabatta, ginnastica, piedi, tacco\n",
      "My answer: scarpa\n",
      "Correct answer: scarpa\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "        {'words': ['sassolino', 'ciabatta', 'ginnastica', 'piedi', 'tacco'], 'correct_answer': 'scarpa'},\n",
    "        {'words': ['signore', 'civile', 'capo', 'perdere', 'settimo'], 'correct_answer': 'anno'},\n",
    "        {'words': ['scherzo', 'rock', 'insolito', 'amaro', 'danza'], 'correct_answer': 'destino'},\n",
    "        {'words': ['sorpresa', 'natale', 'compleanno', 'laurea', 'costoso'], 'correct_answer': 'regalo'},\n",
    "        {'words': ['adele', 'facile', 'dolce', 'grazie', 'forza'], 'correct_answer': 'vita'},\n",
    "    ]\n",
    "\n",
    "\n",
    "# Random index to select a test\n",
    "index = random.randint(0, len(tests) - 1)\n",
    "selected_words = tests[index]['words']\n",
    "correct_answer = tests[index]['correct_answer']\n",
    "\n",
    "# Answer computation\n",
    "answer = compute_answer(selected_words)\n",
    "\n",
    "print(f'Words: {\", \".join(selected_words)}')\n",
    "print(f'My answer: {answer}')\n",
    "print(f'Correct answer: {correct_answer}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea59138689929fdab3e49db7a63d86373d5c14a34dc5888abf301d9cce48d630"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
