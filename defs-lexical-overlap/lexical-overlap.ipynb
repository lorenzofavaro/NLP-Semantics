{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this exercise we compute the similarity between the definitions given by us (unito students) for 4 terms. The purpose of the exercise is to prove that defining a term is more complicated than one might think, especially if the term is abstract and/or generic.\n",
    "#### The terms used for the experiment are:\n",
    "- Emotion\n",
    "- Person\n",
    "- Revenge\n",
    "- Brick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from typing import AnyStr, Set, List, Dict\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing of a sentence\n",
    "def bag_of_words(sentence: AnyStr) -> Set[AnyStr]:\n",
    "    return set(remove_stopwords(tokenize_sentence(remove_punctuation(sentence))))\n",
    "\n",
    "\n",
    "# Remove stopwords from a word list\n",
    "def remove_stopwords(words: List[AnyStr]) -> List[AnyStr]:\n",
    "    return [value.lower() for value in words if value.lower() not in stop_words]\n",
    "\n",
    "\n",
    "# Get tokens from sentence\n",
    "def tokenize_sentence(sentence: AnyStr) -> List[AnyStr]:\n",
    "    words = []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    for tag in nltk.pos_tag(word_tokenize(sentence)):\n",
    "        words.append(lmtzr.lemmatize(tag[0]).lower())\n",
    "    return words\n",
    "\n",
    "\n",
    "# Remove punctuation and multiple spaces\n",
    "def remove_punctuation(sentence: AnyStr) -> AnyStr:\n",
    "    return re.sub('\\s\\s+', ' ', re.sub(r'[^\\w\\s]', '', sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion: [{'concept', 'feel', 'human', 'situation', 'range'}, {'feel'}, {'animal', 'feel'}, {'bad', 'good', 'feel'}, {'sensation', 'arising', 'feeling', 'human', 'form'}, {'mind', 'living', 'percieve'}, {'human', 'feeling', 'express', 'animal'}, {'word', 'entity', 'feel', 'sentiment', 'living', 'express', 'throw', 'body'}, {'moment', 'feel'}, {'ming', 'well', 'experienced', 'happening', 'event', 'feeling', 'sentient'}, {'reation', 'action', 'sentimental'}, {'feel'}, {'love', 'sadness', 'happyness', 'feeling', 'human'}, {'general', 'concept', 'feeling'}, {'deriving', 'feeling', 'human', 'life'}, {'human', 'sensation'}, {'feeling', 'animal'}, {'psychic', 'emotion'}, {'human', 'feel'}, {'sensation', 'positive', 'affect', 'negative', 'mood', 'human'}, {'feeling', 'living'}, {'feeling'}, {'internal', 'external', 'person', 'caused', 'mind'}, {'reaction', 'mental'}, {'strong', 'feeling'}, {'felt', 'living', 'feelingstate'}, {'agent', 'mental'}, {'mood', 'mental'}, {'feeling', 'dued'}, {'physical', 'mental', 'feeling', 'created', 'stimulus', 'emotion'}]\n",
      "\n",
      "Person: [{'human'}, {'human'}, {'precise', 'describe', 'feature', 'person', 'generic', 'single', 'human'}, {'human'}, {'belonging', 'living', 'group', 'human', 'society'}, {'descending', 'mammal', 'ape'}, {'human', 'sentient', 'living', 'entity'}, {'human'}, {'human', 'touch'}, {'human'}, {'human'}, {'living'}, {'human', 'characteristic'}, {'human', 'individual'}, {'feeling', 'animal'}, {'human'}, {'human'}, {'person', 'human'}, {'person', 'human'}, {'person', 'human'}, {'homo', 'sapiens', 'member'}, {'human'}, {'human'}, {'homo', 'individual', 'sapiens', 'specie'}, {'human'}, {'human'}, {'human', 'woman', 'man'}, {'human', 'specific'}, {'human'}, {'living', 'entity'}, {'person', 'single', 'question', 'physical', 'compassion', 'cognitive', 'answer', 'ability', 'walk', 'leg', 'individual', 'experience', 'reason', 'unique', 'complex', 'upright', 'defined', 'love', 'happiness', 'ultimately', 'vary', 'human', 'emotion', 'characteristic'}]\n",
      "\n",
      "Revenge: [{'consequence', 'wrongdoing', 'bad', 'action', 'negative', 'feeling'}, {'describes', 'emotion', 'anger'}, {'describe', 'good', 'entity', 'anger', 'specific', 'person', 'generally', 'classified', 'emotion'}, {'negative', 'emotion'}, {'violence', 'oneself', 'anger', 'arising', 'feeling', 'reaction', 'form'}, {'anger', 'living', 'triggered', 'performed', 'hatred', 'emotion'}, {'feeling', 'foe', 'action', 'anger'}, {'anger'}, {'action', 'generally', 'motivated', 'anger'}, {'anger', 'sentiment', 'lead', 'sentient', 'disillusionment'}, {'person', 'action', 'bad'}, {'emotional', 'harm', 'class', 'reaction', 'emotion'}, {'arising', 'feeling', 'negative'}, {'feeling', 'hurting', 'facing'}, {'desire'}, {'action', 'hurting', 'wrong', 'ha', 'mind', 'committed', 'consists'}, {'feeling', 'hurt', 'smn', 'hurting'}, {'reaction', 'return', 'revenge'}, {'injure', 'feeling', 'response', 'action'}, {'harming', 'consequence', 'hurting', 'person', 'thing', 'ha', 'situation', 'individual', 'intention'}, {'caused', 'emotion'}, {'reaction', 'angry'}, {'person', 'will', 'bad'}, {'reaction', 'wrong', 'mental'}, {'return', 'damaging', 'injury'}, {'damage', 'hurt'}, {'reaction', 'damaging'}, {'mood'}, {'justice', 'desire'}, {'seeking', 'wrong', 'justice', 'type', 'ha', 'retribution', 'revenge'}]\n",
      "\n",
      "Brick: [{'building', 'aim', 'material', 'constructing', 'object', 'clay'}, {'material', 'block', 'construction'}, {'element', 'object', 'construction', 'building', 'basic'}, {'build', 'piece', 'material'}, {'object', 'parallelepiped', 'construction', 'building'}, {'shape', 'resistnat', 'polygonal', 'material', 'construction', 'tool'}, {'shape', 'material', 'construction', 'building', 'size'}, {'build', 'wall', 'object'}, {'build', 'red', 'object', 'construction'}, {'building', 'ei', 'material', 'block', 'generally', 'clay', 'cunstruction'}, {'brick', 'wall', 'es', 'object', 'construction'}, {'build', 'house', 'object', 'clay', 'phyisical'}, {'physical', 'material', 'house', 'construction'}, {'house', 'well', 'object', 'construction'}, {'costruction', 'building', 'material', 'object', 'clay'}, {'build'}, {'material', 'block'}, {'build', 'object', 'building'}, {'material', 'block', 'construction', 'building'}, {'brick', 'object', 'construction', 'building'}, {'build', 'material', 'block', 'construction'}, {'thing', 'build', 'element', 'object'}, {'build', 'material', 'structure', 'clay'}, {'build', 'piece', 'material'}, {'rectangularshaped', 'building', 'object', 'constructing'}, {'build', 'object', 'rectangularshaped', 'construction', 'clay'}, {'material', 'construction'}, {'material', 'construction'}, {'build', 'object'}, {'build', 'object'}, {'brick', 'material', 'ceramic', 'block', 'construction', 'rectangular'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load stop words from file\n",
    "def import_stop_words() -> Set[AnyStr]:\n",
    "    with open('data/stop_words_FULL.txt') as f:\n",
    "        stop_words = {line for line in f.read().splitlines()}\n",
    "    return stop_words\n",
    "\n",
    "\n",
    "# Load definitions and build a map\n",
    "def import_definitions_map() -> Dict[AnyStr, List[Set[AnyStr]]]:\n",
    "    definitions_map = defaultdict(list)\n",
    "    with open('data/definitions.csv') as f:\n",
    "        for line in f.readlines()[1:]:\n",
    "            splits = line.split(\"~|~\")\n",
    "            word = splits[0]\n",
    "            definitions = splits[1:]\n",
    "            for definition in definitions:\n",
    "                if bow_words := bag_of_words(definition):\n",
    "                    definitions_map[word].append(bow_words)\n",
    "    return dict(definitions_map)\n",
    "            \n",
    "\n",
    "stop_words = import_stop_words()\n",
    "definitions_map = import_definitions_map()\n",
    "\n",
    "for word, definitions in definitions_map.items():\n",
    "    print(f\"{word}: {definitions}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(def1, def2) -> float:\n",
    "    # To avoid set of a single string, we do this check\n",
    "    def1 = def1 if type(def1) is set else {def1}\n",
    "    def2 = def2 if type(def2) is set else {def2}\n",
    "\n",
    "    # Union of all the words for two definitions\n",
    "    defs_union = list(def1 | def2)\n",
    "    def_vec1 = []\n",
    "    def_vec2 = []\n",
    "\n",
    "    # Binary vectors computation that we'll use to compute cosine score\n",
    "    for word in defs_union:\n",
    "        def_vec1.append(1) if word in def1 else def_vec1.append(0)\n",
    "        def_vec2.append(1) if word in def2 else def_vec2.append(0)\n",
    "    \n",
    "    # Cosine similarity computation (overlap)\n",
    "    cosine_score = dot(def_vec1, def_vec2) / (norm(def_vec1) * norm(def_vec2))\n",
    "    return cosine_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine scores for all the possible combinations between definitions\n",
    "def compute_scores(definitions_map: Dict[AnyStr, List[Set[AnyStr]]]) -> float:\n",
    "    scores = dict()\n",
    "    for concept, definitions in definitions_map.items():\n",
    "        avg_similarity = 0\n",
    "        combinations_count = 0\n",
    "\n",
    "        for def1 in definitions:\n",
    "            for def2 in definitions:\n",
    "                if def1 != def2:\n",
    "                    avg_similarity += cosine_similarity(def1, def2)\n",
    "                    combinations_count += 1\n",
    "        \n",
    "        # Compute average similarity\n",
    "        scores[concept] = avg_similarity / combinations_count\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Compute mean score for the 3 most frequent words\n",
    "def most_frequent_words_score(definitions_map: Dict[AnyStr, List[Set[AnyStr]]], words_num: int = 3) -> float:\n",
    "    scores = dict()\n",
    "    for concept, definitions in definitions_map.items():\n",
    "        concept_counter = Counter()\n",
    "        \n",
    "        for definition in definitions:\n",
    "            concept_counter.update(definition)\n",
    "        \n",
    "        frequent_words_counter = {entry[0] : 0 for entry in concept_counter.most_common(words_num)}\n",
    "        print(f\"The most frequent words for {concept} are: {list(frequent_words_counter.keys())}\")\n",
    "\n",
    "        for definition in definitions:\n",
    "            for word in frequent_words_counter:\n",
    "                if word in definition:\n",
    "                    frequent_words_counter[word] += 1\n",
    "        \n",
    "        mean = 0\n",
    "        for word, count in frequent_words_counter.items():\n",
    "            mean += count/len(definitions)\n",
    "\n",
    "        scores[concept] = mean/words_num\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average definition cosine similarity: \n",
      "{'Emotion': 0.11487493413331017, 'Person': 0.3086137065020268, 'Revenge': 0.07504048944139909, 'Brick': 0.2985398157677549}\n",
      "\n",
      "The most frequent words for Emotion are: ['feeling', 'feel', 'human']\n",
      "The most frequent words for Person are: ['human', 'person', 'living']\n",
      "The most frequent words for Revenge are: ['anger', 'feeling', 'action']\n",
      "The most frequent words for Brick are: ['material', 'object', 'construction']\n",
      "Average definition mean score for the most 3 frequent words: \n",
      "{'Emotion': 0.3111111111111111, 'Person': 0.3655913978494623, 'Revenge': 0.2333333333333333, 'Brick': 0.5161290322580645}\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine scores for all the definitions of the words\n",
    "scores = compute_scores(definitions_map)\n",
    "print(f\"Average definition cosine similarity: \\n{scores}\\n\")\n",
    "\n",
    "# Compute mean scores for only the most 3 frequent words in the definitions\n",
    "mfw_score = most_frequent_words_score(definitions_map, 3)\n",
    "print(f\"Average definition mean score for the most 3 frequent words: \\n{mfw_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "1. Through the cosine similarity, we see that the similarity between the definitions is higher for \"Person\" that is our most generic concepts\n",
    "2. Through the most frequent words similarity, instead we got that the similarity is highest for the definition of \"Brick\", followed by \"Person\" that we got before\n",
    "\n",
    "As we can see, both the scores method return low scores, therefore we can conclude that (as we expected) giving definitions to a concept is really a hard task!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e624e3332703bdf7ee5424ba9758cd660f9e1e58c0307d464007169a6bf7434"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
