{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this exercise we compute the similarity between the definitions given by us (unito students) for 4 terms. The purpose of the exercise is to prove that defining a term is more complicated than one might think, especially if the term is abstract and/or generic.\n",
    "#### The terms used for the experiment are:\n",
    "- Emotion\n",
    "- Person\n",
    "- Revenge\n",
    "- Brick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from typing import Set, List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion: [{'concept', 'feel', 'human', 'situation', 'range'}, {'feel'}, {'animal', 'feel'}, {'bad', 'good', 'feel'}, {'sensation', 'arising', 'feeling', 'human', 'form'}, {'mind', 'living', 'percieve'}, {'human', 'feeling', 'express', 'animal'}, {'word', 'entity', 'feel', 'sentiment', 'living', 'express', 'throw', 'body'}, {'moment', 'feel'}, {'ming', 'well', 'experienced', 'happening', 'event', 'feeling', 'sentient'}, {'reation', 'action', 'sentimental'}, {'feel'}, {'love', 'sadness', 'happyness', 'feeling', 'human'}, {'general', 'concept', 'feeling'}, {'deriving', 'feeling', 'human', 'life'}, {'human', 'sensation'}, {'feeling', 'animal'}, {'psychic', 'emotion'}, {'human', 'feel'}, {'sensation', 'positive', 'affect', 'negative', 'mood', 'human'}, {'feeling', 'living'}, {'feeling'}, {'internal', 'external', 'person', 'caused', 'mind'}, {'reaction', 'mental'}, {'strong', 'feeling'}, {'felt', 'living', 'feelingstate'}, {'agent', 'mental'}, {'mood', 'mental'}, {'feeling', 'dued'}, {'physical', 'mental', 'feeling', 'created', 'stimulus', 'emotion'}]\n",
      "\n",
      "Person: [{'human'}, {'human'}, {'precise', 'describe', 'feature', 'person', 'generic', 'single', 'human'}, {'human'}, {'belonging', 'living', 'group', 'human', 'society'}, {'descending', 'mammal', 'ape'}, {'human', 'sentient', 'living', 'entity'}, {'human'}, {'human', 'touch'}, {'human'}, {'human'}, {'living'}, {'human', 'characteristic'}, {'human', 'individual'}, {'feeling', 'animal'}, {'human'}, {'human'}, {'person', 'human'}, {'person', 'human'}, {'person', 'human'}, {'homo', 'sapiens', 'member'}, {'human'}, {'human'}, {'homo', 'individual', 'sapiens', 'specie'}, {'human'}, {'human'}, {'human', 'woman', 'man'}, {'human', 'specific'}, {'human'}, {'living', 'entity'}, {'person', 'single', 'question', 'physical', 'compassion', 'cognitive', 'answer', 'ability', 'walk', 'leg', 'individual', 'experience', 'reason', 'unique', 'complex', 'upright', 'defined', 'love', 'happiness', 'ultimately', 'vary', 'human', 'emotion', 'characteristic'}]\n",
      "\n",
      "Revenge: [{'consequence', 'wrongdoing', 'bad', 'action', 'negative', 'feeling'}, {'describes', 'emotion', 'anger'}, {'describe', 'good', 'entity', 'anger', 'specific', 'person', 'generally', 'classified', 'emotion'}, {'negative', 'emotion'}, {'violence', 'oneself', 'anger', 'arising', 'feeling', 'reaction', 'form'}, {'anger', 'living', 'triggered', 'performed', 'hatred', 'emotion'}, {'feeling', 'foe', 'action', 'anger'}, {'anger'}, {'action', 'generally', 'motivated', 'anger'}, {'anger', 'sentiment', 'lead', 'sentient', 'disillusionment'}, {'person', 'action', 'bad'}, {'emotional', 'harm', 'class', 'reaction', 'emotion'}, {'arising', 'feeling', 'negative'}, {'feeling', 'hurting', 'facing'}, {'desire'}, {'action', 'hurting', 'wrong', 'ha', 'mind', 'committed', 'consists'}, {'feeling', 'hurt', 'smn', 'hurting'}, {'reaction', 'return', 'revenge'}, {'injure', 'feeling', 'response', 'action'}, {'harming', 'consequence', 'hurting', 'person', 'thing', 'ha', 'situation', 'individual', 'intention'}, {'caused', 'emotion'}, {'reaction', 'angry'}, {'person', 'will', 'bad'}, {'reaction', 'wrong', 'mental'}, {'return', 'damaging', 'injury'}, {'damage', 'hurt'}, {'reaction', 'damaging'}, {'mood'}, {'justice', 'desire'}, {'seeking', 'wrong', 'justice', 'type', 'ha', 'retribution', 'revenge'}]\n",
      "\n",
      "Brick: [{'building', 'aim', 'material', 'constructing', 'object', 'clay'}, {'material', 'block', 'construction'}, {'element', 'object', 'construction', 'building', 'basic'}, {'build', 'piece', 'material'}, {'object', 'parallelepiped', 'construction', 'building'}, {'shape', 'resistnat', 'polygonal', 'material', 'construction', 'tool'}, {'shape', 'material', 'construction', 'building', 'size'}, {'build', 'wall', 'object'}, {'build', 'red', 'object', 'construction'}, {'building', 'ei', 'material', 'block', 'generally', 'clay', 'cunstruction'}, {'brick', 'wall', 'es', 'object', 'construction'}, {'build', 'house', 'object', 'clay', 'phyisical'}, {'physical', 'material', 'house', 'construction'}, {'house', 'well', 'object', 'construction'}, {'costruction', 'building', 'material', 'object', 'clay'}, {'build'}, {'material', 'block'}, {'build', 'object', 'building'}, {'material', 'block', 'construction', 'building'}, {'brick', 'object', 'construction', 'building'}, {'build', 'material', 'block', 'construction'}, {'thing', 'build', 'element', 'object'}, {'build', 'material', 'structure', 'clay'}, {'build', 'piece', 'material'}, {'rectangularshaped', 'building', 'object', 'constructing'}, {'build', 'object', 'rectangularshaped', 'construction', 'clay'}, {'material', 'construction'}, {'material', 'construction'}, {'build', 'object'}, {'build', 'object'}, {'brick', 'material', 'ceramic', 'block', 'construction', 'rectangular'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root_dir = '..'\n",
    "\n",
    "# Load stop words from file\n",
    "def import_stop_words() -> Set[str]:\n",
    "    with open(f'{root_dir}/common-data/stop_words_FULL.txt') as f:\n",
    "        stop_words = {line for line in f.read().splitlines()}\n",
    "    return stop_words\n",
    "\n",
    "\n",
    "# Load definitions and build a map\n",
    "def import_definitions_map() -> Dict[str, List[Set[str]]]:\n",
    "    definitions_map = defaultdict(list)\n",
    "    with open(f'{root_dir}/common-data/definitions.csv') as f:\n",
    "\n",
    "        for line in f.readlines()[1:]:\n",
    "            splits = line.split(\"~|~\")\n",
    "            word = splits[0]\n",
    "            definitions = splits[1:]\n",
    "            \n",
    "            for definition in definitions:\n",
    "                if bow_words := bag_of_words(definition):\n",
    "                    definitions_map[word].append(bow_words)\n",
    "\n",
    "    return dict(definitions_map)\n",
    "            \n",
    "\n",
    "stop_words = import_stop_words()\n",
    "definitions_map = import_definitions_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing of a sentence\n",
    "def bag_of_words(sentence: str) -> Set[str]:\n",
    "    return set(remove_stopwords(tokenize_sentence(remove_punctuation(sentence))))\n",
    "\n",
    "\n",
    "# Remove stopwords from a word list\n",
    "def remove_stopwords(words: List[str]) -> List[str]:\n",
    "    return [value.lower() for value in words if value.lower() not in stop_words]\n",
    "\n",
    "\n",
    "# Get tokens from sentence\n",
    "def tokenize_sentence(sentence: str) -> List[str]:\n",
    "    words = []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    for tag in nltk.pos_tag(word_tokenize(sentence)):\n",
    "        words.append(lmtzr.lemmatize(tag[0]).lower())\n",
    "    return words\n",
    "\n",
    "\n",
    "# Remove punctuation and multiple spaces\n",
    "def remove_punctuation(sentence: str) -> str:\n",
    "    return re.sub('\\s\\s+', ' ', re.sub(r'[^\\w\\s]', '', sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(def1, def2) -> float:\n",
    "    # To avoid set of a single string, we do this check\n",
    "    def1 = def1 if type(def1) is set else {def1}\n",
    "    def2 = def2 if type(def2) is set else {def2}\n",
    "\n",
    "    # Union of all the words for two definitions\n",
    "    defs_union = list(def1 | def2)\n",
    "    def_vec1 = []\n",
    "    def_vec2 = []\n",
    "\n",
    "    # Binary vectors computation that we'll use to compute cosine score\n",
    "    for word in defs_union:\n",
    "        def_vec1.append(1) if word in def1 else def_vec1.append(0)\n",
    "        def_vec2.append(1) if word in def2 else def_vec2.append(0)\n",
    "    \n",
    "    # Cosine similarity computation (overlap)\n",
    "    cosine_score = dot(def_vec1, def_vec2) / (norm(def_vec1) * norm(def_vec2))\n",
    "    return cosine_score\n",
    "\n",
    "\n",
    "# Compute cosine scores for all the possible combinations between definitions\n",
    "def compute_scores(definitions_map: Dict[str, List[Set[str]]]) -> float:\n",
    "    scores = dict()\n",
    "    for concept, definitions in definitions_map.items():\n",
    "        avg_similarity = 0\n",
    "        combinations_count = 0\n",
    "\n",
    "        for def1 in definitions:\n",
    "            for def2 in definitions:\n",
    "                if def1 != def2:\n",
    "                    avg_similarity += cosine_similarity(def1, def2)\n",
    "                    combinations_count += 1\n",
    "        \n",
    "        # Compute average similarity\n",
    "        scores[concept] = avg_similarity / combinations_count\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Find the |words_num| most frequent words present in the definitions\n",
    "def find_MFW(definitions: List[Set[str]], words_num: int) -> List[str]:\n",
    "    concept_counter = Counter()\n",
    "        \n",
    "    for definition in definitions:\n",
    "        concept_counter.update(definition)\n",
    "    \n",
    "    most_frequent_words = [entry[0] for entry in concept_counter.most_common(words_num)]\n",
    "    return most_frequent_words\n",
    "\n",
    "\n",
    "# Compute mean score for the 3 most frequent words\n",
    "def most_frequent_words_score(definitions_map: Dict[str, List[Set[str]]], words_num: int = 3) -> float:\n",
    "    scores = dict()\n",
    "    for concept, definitions in definitions_map.items():\n",
    "        frequent_words_counter = {word : 0 for word in find_MFW(definitions, words_num)}\n",
    "        print(f\"The most frequent words for {concept} are: {list(frequent_words_counter.keys())}\")\n",
    "\n",
    "        for definition in definitions:\n",
    "            for word in frequent_words_counter:\n",
    "                if word in definition:\n",
    "                    frequent_words_counter[word] += 1\n",
    "        \n",
    "        mean = 0\n",
    "        for word, count in frequent_words_counter.items():\n",
    "            mean += count/len(definitions)\n",
    "\n",
    "        scores[concept] = mean/words_num\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average definition cosine similarity: \n",
      "{'Emotion': 0.11487493413331017, 'Person': 0.3086137065020268, 'Revenge': 0.07504048944139909, 'Brick': 0.2985398157677549}\n",
      "\n",
      "The most frequent words for Emotion are: ['feeling', 'feel', 'human', 'living', 'mental']\n",
      "The most frequent words for Person are: ['human', 'person', 'living', 'individual', 'single']\n",
      "The most frequent words for Revenge are: ['anger', 'feeling', 'action', 'emotion', 'reaction']\n",
      "The most frequent words for Brick are: ['material', 'object', 'construction', 'build', 'building']\n",
      "Average definition mean score for the most 5 frequent words: \n",
      "{'Emotion': 0.24, 'Person': 0.25161290322580643, 'Revenge': 0.21999999999999997, 'Brick': 0.4580645161290323}\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine scores for all the definitions of the words\n",
    "scores = compute_scores(definitions_map)\n",
    "print(f\"Average definition cosine similarity: \\n{scores}\\n\")\n",
    "\n",
    "# Compute mean scores for only the most 3 frequent words in the definitions\n",
    "words_num = 5\n",
    "mfw_score = most_frequent_words_score(definitions_map, words_num)\n",
    "print(f\"Average definition mean score for the most {words_num} frequent words: \\n{mfw_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "1. Through the cosine similarity, we see that the similarity between the definitions is higher for \"Person\" that is our most generic concepts\n",
    "2. Through the most frequent words similarity, instead we got that the similarity is highest for the definition of \"Brick\", followed by \"Person\" that we got before\n",
    "\n",
    "As we can see, both the scores method return low scores, therefore we can conclude that (as we expected) giving definitions to a concept is really a hard task!\n",
    "Furthermore, we observe that (as we have seen during the lessons) the similarity is higher for the concrete concepts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c75d46810c3de735ca95efd8dfb7d6dbf93a2c06ee0538e38e90ee10bc420c21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
